import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy.stats import chi2_contingency

def load_datasets(file_paths):
    """
    Loads multiple CSV files into pandas DataFrames.

    Args:
        file_paths (dict): A dictionary where keys are dataframe names
                           and values are the file paths to the CSVs.

    Returns:
        dict: A dictionary of pandas DataFrames.
    """
    dataframes = {}
    print("--- 1. Loading Datasets ---")
    try:
        for name, path in file_paths.items():
            dataframes[name] = pd.read_csv(path)
        print("All required datasets loaded successfully.")
    except FileNotFoundError as e:
        print(f"Error: {e}. Please ensure all data files are in the correct directory.")
        return None
    return dataframes

def clean_and_prepare_data(dataframes):
    """
    Cleans and preprocesses the raw dataframes.

    This function handles missing values, converts data types,
    and removes duplicate entries.

    Args:
        dataframes (dict): The dictionary of raw pandas DataFrames.

    Returns:
        dict: The dictionary of cleaned pandas DataFrames.
    """
    print("\n--- 2. Cleaning and Preparing Data ---")

    # --- Set pandas display options ---
    pd.set_option('display.max_columns', None)
    pd.set_option('display.max_rows', 100)
    pd.set_option('display.float_format', lambda x: f'{x:.2f}')

    # --- Clean df_mql ---
    df_mql = dataframes['df_mql']
    df_mql['first_contact_date'] = pd.to_datetime(df_mql['first_contact_date'], errors='coerce')
    df_mql.dropna(subset=['first_contact_date'], inplace=True)
    df_mql.drop_duplicates(inplace=True)
    df_mql['origin'].fillna('unknown', inplace=True)
    dataframes['df_mql'] = df_mql

    # --- Clean df_closed_deals ---
    df_closed_deals = dataframes['df_closed_deals']
    df_closed_deals['won_date'] = pd.to_datetime(df_closed_deals['won_date'], errors='coerce')
    df_closed_deals.dropna(subset=['won_date', 'seller_id'], inplace=True)
    df_closed_deals['business_segment'].fillna('unknown', inplace=True)
    df_closed_deals['lead_type'].fillna('unknown', inplace=True)
    df_closed_deals['lead_behaviour_profile'].fillna('unknown', inplace=True)
    df_closed_deals['has_company'] = df_closed_deals['has_company'].astype(bool)
    df_closed_deals['has_gtin'] = df_closed_deals['has_gtin'].astype(bool)
    df_closed_deals['average_stock'].fillna('unknown', inplace=True)
    df_closed_deals['business_type'].fillna('unknown', inplace=True)
    df_closed_deals['declared_product_catalog_size'].fillna(0, inplace=True)
    df_closed_deals['declared_monthly_revenue'].fillna(0, inplace=True)
    dataframes['df_closed_deals'] = df_closed_deals

    # --- Clean df_orders ---
    df_orders = dataframes['df_orders']
    date_cols_orders = [
        'order_purchase_timestamp', 'order_approved_at',
        'order_delivered_carrier_date', 'order_delivered_customer_date',
        'order_estimated_delivery_date'
    ]
    for col in date_cols_orders:
        df_orders[col] = pd.to_datetime(df_orders[col], errors='coerce')
    dataframes['df_orders'] = df_orders

    # --- Clean df_reviews ---
    df_reviews = dataframes['df_reviews']
    df_reviews['review_creation_date'] = pd.to_datetime(df_reviews['review_creation_date'], errors='coerce')
    df_reviews['review_answer_timestamp'] = pd.to_datetime(df_reviews['review_answer_timestamp'], errors='coerce')
    df_reviews['review_comment_title'].fillna('No Title', inplace=True)
    df_reviews['review_comment_message'].fillna('No Message', inplace=True)
    dataframes['df_reviews'] = df_reviews
    
    # --- Clean df_order_items ---
    df_order_items = dataframes['df_order_items']
    df_order_items['shipping_limit_date'] = pd.to_datetime(df_order_items['shipping_limit_date'], errors='coerce')
    dataframes['df_order_items'] = df_order_items

    # --- Clean df_products ---
    df_products = dataframes['df_products']
    df_products['product_category_name'].fillna('unknown', inplace=True)
    
    # Fill numerical product attributes with the median
    numeric_cols = [
        'product_name_lenght', 'product_description_lenght', 'product_photos_qty',
        'product_weight_g', 'product_length_cm', 'product_height_cm', 'product_width_cm'
    ]
    for col in numeric_cols:
        median_value = df_products[col].median()
        df_products[col].fillna(median_value, inplace=True)
    dataframes['df_products'] = df_products

    print("Data cleaning and preparation complete.")
    return dataframes

def main():
    """
    Main function to run the data analysis pipeline.
    """
    # Define the file paths for the datasets
    file_paths = {
        "df_closed_deals": "olist_closed_deals_dataset.csv",
        "df_mql": "olist_marketing_qualified_leads_dataset.csv",
        "df_sellers": "olist_sellers_dataset.csv",
        "df_order_items": "olist_order_items_dataset.csv",
        "df_orders": "olist_orders_dataset.csv",
        "df_reviews": "olist_order_reviews_dataset.csv",
        "df_products": "olist_products_dataset.csv",
        "df_product_category_translation": "product_category_name_translation.csv"
    }

    # Load the datasets
    dataframes = load_datasets(file_paths)

    if dataframes:
        # Clean and prepare the data
        cleaned_data = clean_and_prepare_data(dataframes)
        
        # You can now proceed with your data analysis using the 'cleaned_data' dictionary.
        # For example, to access the cleaned deals dataframe:
        # deals_df = cleaned_data['df_closed_deals']
        # print("\n--- Sample of Cleaned Closed Deals Data ---")
        # print(deals_df.head())
        # print(deals_df.info())

if __name__ == "__main__":
    main()
